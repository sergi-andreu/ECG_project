{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27151336-ff7d-4302-bb7b-3df6ebcd988a",
   "metadata": {},
   "source": [
    "# Create arrays\n",
    "\n",
    "This notebook contains code for reading the *ptb-xl* data and converting useful files to numpy arrays, corresponding to the different folds, which would be later uploaded into my personal drive for further access in google collab.\n",
    "\n",
    "This is done to reduce the computing time associated to loading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6ad41-bc1e-4e0e-9e73-c02ca16ce7f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download the data\n",
    "\n",
    "If not done, download the physionet data. I have done this in the terminal, but I add the line code here for completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0390f684-e274-4804-88f8-f59f29afdfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -r -N -c -np https://physionet.org/files/ptb-xl/1.0.2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0beacb-ff73-460f-84cc-055bd8970f02",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10832eec-9a4f-4658-8e7a-7d5c77a05a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81f27c-1ec8-4e19-9db5-ee396d76a118",
   "metadata": {},
   "source": [
    "## Load signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac996db-d7b4-4472-a9c4-292d71de627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and convert signal data\n",
    "path = \"data/\" # Path where the data is stored. \n",
    "# I renamed the data folder manually after downloading the physionet data to \"data\"\n",
    "\n",
    "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def load_raw_data(df, path):\n",
    "    data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    return data\n",
    "\n",
    "X = load_raw_data(Y, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b5cfad-2a86-440d-a3d6-8b2321903487",
   "metadata": {},
   "source": [
    "## Save signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c88d4-11b6-4106-a6a4-d144bdcffca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    name = f\"data/nparrays/{str(i).zfill(2)}\"\n",
    "    X_train = X[np.where(Y.strat_fold == i)]\n",
    "    np.save(name, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ce7f54-e6f2-49ba-878c-6e69cc35a2f0",
   "metadata": {},
   "source": [
    "## Aggregate the diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea70d6f5-2eb7-4f9f-9878-e8f3f834d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced0239-2908-41da-b76a-7826d8f5cb60",
   "metadata": {},
   "source": [
    "## Save label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3227ed2e-5fa8-400f-8585-66af81316b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "enc = MultiLabelBinarizer(classes = [\"NORM\", \"MI\", \"STTC\", \"CD\", \"HYP\"])\n",
    "\n",
    "for i in range(1, 11):\n",
    "    name = f\"data/nparrays/labels/{str(i).zfill(2)}\"\n",
    "    Y_ = Y[(Y.strat_fold == i)].diagnostic_superclass.tolist()\n",
    "    Y_ = enc.fit_transform(Y_)\n",
    "    \n",
    "    np.save(name, Y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069003a6-2882-42c6-aa31-a8b01af27adb",
   "metadata": {},
   "source": [
    "## Compute heart beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d6643-8c0d-4d05-9a87-a470f0a782ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bpm(df, path):\n",
    "    HB = []\n",
    "    for idx, f in enumerate(df.filename_lr):\n",
    "        sig, fields = wfdb.rdsamp(path+f)\n",
    "        qrs_inds = [wfdb.processing.XQRS(sig=sig[:,ch_idx],fs=fields['fs']) for ch_idx in range(12)]\n",
    "        for qr in qrs_inds:\n",
    "            qr.detect(verbose=False)\n",
    "        \n",
    "        intervals = [wfdb.processing.calc_rr(qrs_inds[ch_idx].qrs_inds) for ch_idx in range(12)]\n",
    "        bpm = [wfdb.processing.calc_mean_hr(intervals[ch_idx], fs=fields[\"fs\"]) for ch_idx in range(12)]\n",
    "        \n",
    "        if idx % 100 == 0: print(f\"Processed {idx} samples\")\n",
    "        HB += [bpm]\n",
    "    return HB\n",
    "\n",
    "BPM = compute_bpm(Y, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54ccee-bc10-4e3f-8914-a1f4158f5478",
   "metadata": {},
   "source": [
    "## Save heart beat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b2619-a0cf-4038-bfb4-d7d7e5268049",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    name = f\"data/nparrays/bpm/{str(i).zfill(2)}\"\n",
    "    X_ = BPM[np.where(Y.strat_fold == i)[0]]\n",
    "    np.save(name, X_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
